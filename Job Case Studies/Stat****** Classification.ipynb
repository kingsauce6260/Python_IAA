{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Classification\n",
    "\n",
    "Step 1 - Clean and prepare your data: \n",
    "There are several entries where values have been deleted to simulate dirty data. Please clean the data with whatever method(s) you believe is best/most suitable. Note that some of the missing values are truly blank (unknown answers). Success in this exercise typically involves feature engineering and avoiding data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "data = pd.read_csv('/Users/thomasgow/Documents/IAA/Jobs/StateFarm/exercise_05_train.csv')\n",
    "test = pd.read_csv('/Users/thomasgow/Documents/IAA/Jobs/StateFarm/exercise_05_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963686</td>\n",
       "      <td>6.627185</td>\n",
       "      <td>-45.224008</td>\n",
       "      <td>9.477531</td>\n",
       "      <td>-3.216532</td>\n",
       "      <td>13.216874</td>\n",
       "      <td>9.754747</td>\n",
       "      <td>5.245851</td>\n",
       "      <td>-1.102918</td>\n",
       "      <td>-2.867482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988829</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.380664</td>\n",
       "      <td>-16.388994</td>\n",
       "      <td>5.326730</td>\n",
       "      <td>4.187294</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>-3.646841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.770062</td>\n",
       "      <td>-23.610459</td>\n",
       "      <td>-0.964003</td>\n",
       "      <td>-31.981497</td>\n",
       "      <td>-10.294599</td>\n",
       "      <td>-10.240251</td>\n",
       "      <td>-1.518888</td>\n",
       "      <td>-1.675208</td>\n",
       "      <td>0.498134</td>\n",
       "      <td>-0.614390</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.162863</td>\n",
       "      <td>1.809807</td>\n",
       "      <td>asia</td>\n",
       "      <td>2.500590</td>\n",
       "      <td>4.338834</td>\n",
       "      <td>-1.583225</td>\n",
       "      <td>-1.172417</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.962401</td>\n",
       "      <td>-8.349849</td>\n",
       "      <td>23.248891</td>\n",
       "      <td>-24.196879</td>\n",
       "      <td>8.937480</td>\n",
       "      <td>10.965000</td>\n",
       "      <td>-7.490596</td>\n",
       "      <td>-3.025094</td>\n",
       "      <td>0.595807</td>\n",
       "      <td>0.382732</td>\n",
       "      <td>...</td>\n",
       "      <td>1.779660</td>\n",
       "      <td>9.528113</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.396475</td>\n",
       "      <td>7.839188</td>\n",
       "      <td>10.402396</td>\n",
       "      <td>1.288991</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>-4.132316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.780709</td>\n",
       "      <td>-25.261584</td>\n",
       "      <td>1.383115</td>\n",
       "      <td>-11.786929</td>\n",
       "      <td>7.993078</td>\n",
       "      <td>-11.245752</td>\n",
       "      <td>-2.607351</td>\n",
       "      <td>-3.513896</td>\n",
       "      <td>-0.614235</td>\n",
       "      <td>-1.453979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203206</td>\n",
       "      <td>4.892248</td>\n",
       "      <td>asia</td>\n",
       "      <td>0.744317</td>\n",
       "      <td>7.380982</td>\n",
       "      <td>7.599323</td>\n",
       "      <td>-8.022884</td>\n",
       "      <td>-0.067624</td>\n",
       "      <td>-1.796198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.211541</td>\n",
       "      <td>1.119963</td>\n",
       "      <td>7.512938</td>\n",
       "      <td>21.987312</td>\n",
       "      <td>-5.155392</td>\n",
       "      <td>10.339416</td>\n",
       "      <td>3.045180</td>\n",
       "      <td>-0.619230</td>\n",
       "      <td>-0.928068</td>\n",
       "      <td>0.405024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248724</td>\n",
       "      <td>18.694990</td>\n",
       "      <td>asia</td>\n",
       "      <td>1.703196</td>\n",
       "      <td>-11.552129</td>\n",
       "      <td>0.381768</td>\n",
       "      <td>-3.550471</td>\n",
       "      <td>-0.055180</td>\n",
       "      <td>-3.344490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0         x1         x2         x3         x4         x5        x6  \\\n",
       "0  0.963686   6.627185 -45.224008   9.477531  -3.216532  13.216874  9.754747   \n",
       "1 -1.770062 -23.610459  -0.964003 -31.981497 -10.294599 -10.240251 -1.518888   \n",
       "2  9.962401  -8.349849  23.248891 -24.196879   8.937480  10.965000 -7.490596   \n",
       "3 -5.780709 -25.261584   1.383115 -11.786929   7.993078 -11.245752 -2.607351   \n",
       "4  1.211541   1.119963   7.512938  21.987312  -5.155392  10.339416  3.045180   \n",
       "\n",
       "         x7        x8        x9  ...       x91        x92   x93       x94  \\\n",
       "0  5.245851 -1.102918 -2.867482  ...  0.988829   0.313772  asia  1.380664   \n",
       "1 -1.675208  0.498134 -0.614390  ... -2.162863   1.809807  asia  2.500590   \n",
       "2 -3.025094  0.595807  0.382732  ...  1.779660   9.528113  asia  1.396475   \n",
       "3 -3.513896 -0.614235 -1.453979  ... -0.203206   4.892248  asia  0.744317   \n",
       "4 -0.619230 -0.928068  0.405024  ...  0.248724  18.694990  asia  1.703196   \n",
       "\n",
       "         x95        x96       x97       x98       x99  y  \n",
       "0 -16.388994   5.326730  4.187294  0.045549 -3.646841  0  \n",
       "1   4.338834  -1.583225 -1.172417  0.011216  0.097180  0  \n",
       "2   7.839188  10.402396  1.288991  0.008209 -4.132316  0  \n",
       "3   7.380982   7.599323 -8.022884 -0.067624 -1.796198  0  \n",
       "4 -11.552129   0.381768 -3.550471 -0.055180 -3.344490  0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappers to clean categories\n",
    "month_mapper = {'January':1,\n",
    "                'Feb':2,\n",
    "                'Mar':3,\n",
    "                'Apr':4,\n",
    "                'May':5,\n",
    "                'Jun':6,\n",
    "                'July':7,\n",
    "                'Aug':8,\n",
    "                'sept.':9,\n",
    "                'Oct':10,\n",
    "                'Nov':11,\n",
    "                'Dev':12\n",
    "               }\n",
    "\n",
    "day_mapper = {'monday':1,\n",
    "              'tuesday':2,\n",
    "              'wed':3,\n",
    "              'wednesday':3,\n",
    "              'thurday':4,\n",
    "              'thur':4,\n",
    "              'tuesday':2,\n",
    "              'friday':5,\n",
    "              'fri':5\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    \"\"\" Cleans the DataFrame \"\"\"\n",
    "    \n",
    "    # Clean x41 and x45\n",
    "    # Removes the $ from x41\n",
    "    df.x41 = df.x41.str.replace('$', '').astype(float)\n",
    "\n",
    "    # Turns x45 into decimal\n",
    "    df.x45 = df.x45.str.replace('%', '').astype(float)\n",
    "    df.x45 = df.x45/100\n",
    "\n",
    "    # Turns categorical variables into number values\n",
    "    df['x68'] = df['x68'].replace(month_mapper)\n",
    "    df['x35'] = df['x35'].replace(day_mapper)\n",
    "\n",
    "    # Changing the data type of the below mentioned columns and \n",
    "    change_cols=['x34', 'x35', 'x68', 'x93']\n",
    "\n",
    "    #changing data type\n",
    "    df[change_cols]=data[change_cols].astype('category')\n",
    "\n",
    "    # Create codes for nominal variables\n",
    "    df[\"x34\"] = df[\"x34\"].cat.codes\n",
    "    df[\"x93\"] = df[\"x93\"].cat.codes\n",
    "\n",
    "    # Turning -1's back into NA's for imputing\n",
    "    df.loc[(df.x93 == -1),'x93']=np.nan\n",
    "    df.loc[(df.x34 == -1),'x34']=np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Datasets\n",
    "data = cleaning(data)\n",
    "test = cleaning(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual proportion of target variable\n",
    "sns.set(font_scale=1.4)\n",
    "data['y'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Y\", labelpad=14)\n",
    "plt.ylabel(\"Count of Y\", labelpad=14)\n",
    "plt.title(\"Target Variable Distribution\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0 strongly correlated values with y:\n",
      "Series([], Name: y, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Check variables highly correlated with y\n",
    "df_num = data.select_dtypes(include = ['float64', 'int64'])\n",
    "df_num_corr = df_num.corr()['y'][:-1]\n",
    "highest_corr = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)\n",
    "print(\"There is {} strongly correlated values with y:\\n{}\".format(len(highest_corr), highest_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    \"Impute missing values\"\n",
    "    # Impute missing values \n",
    "    imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "    imputed_df = imputer.fit_transform(df)\n",
    "    imputed_df = pd.DataFrame(imputed_df)\n",
    "    col_names = list(df.columns)\n",
    "    imputed_df.columns = col_names\n",
    "    \n",
    "    # Round Imputed Categorical Data\n",
    "    imputed_df['x34'] = imputed_df['x34'].round(decimals=0)\n",
    "    imputed_df['x35'] = imputed_df['x35'].round(decimals=0)\n",
    "    imputed_df['x68'] = imputed_df['x68'].round(decimals=0)\n",
    "    imputed_df['x39'] = imputed_df['x93'].round(decimals=0)\n",
    "    \n",
    "    # Safegaurd values aren't more than max category\n",
    "    imputed_df.loc[(imputed_df.x34 > 9),'x34']=9\n",
    "    imputed_df.loc[(imputed_df.x35 > 5),'x35']=5\n",
    "    imputed_df.loc[(imputed_df.x68 > 12),'x68']=12\n",
    "    imputed_df.loc[(imputed_df.x93 > 2),'x93']=2\n",
    "    \n",
    "    # Return DF\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test\n",
    "def train_test(data):\n",
    "    \"\"\"Creates X_train, y_train, X_valid, y_valid\"\"\"\n",
    "    rand_rows = np.random.rand(len(data)) < 0.6\n",
    "    train = data[rand_rows]\n",
    "    valid = data[~rand_rows]\n",
    "    y_train = train['y']\n",
    "    X_train = train.drop(['y'], axis=1)\n",
    "    y_valid = valid['y']\n",
    "    X_valid = valid.drop(['y'], axis=1)\n",
    "    return y_train, X_train, y_valid, X_valid\n",
    "\n",
    "y_train, X_train, y_valid, X_valid = train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute dataset\n",
    "imputed_training = impute(X_train)\n",
    "imputed_validation = impute(X_valid)\n",
    "imputed_test = impute(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking into potentially removing outliers and scaling the variables I decided not to, because of potential data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23992\n",
      "17924\n"
     ]
    }
   ],
   "source": [
    "# Looking into outliers\n",
    "temp = imputed_training.copy()\n",
    "print(len(temp))\n",
    "temp = temp[(np.abs(stats.zscore(temp)) < 3).all(axis=1)]\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to limit data leakage I tried to minimally \"clean\" because if you perform feature selection on all of the data and then cross-validate then the test data fold was also used to choose the features and this may bias performance analysis. Also after running models 1-7 below, and seeing the high performance of the models I decided it was not worth the potential data leakage.\n",
    "\n",
    "## Step 2 - Build your models: \n",
    "Task: Please use two different machine learning/statistical algorithms to develop a total of two models. Please include comments that document choices you make(such as those for feature engineering and for model tuning). \n",
    "\n",
    "I selected classification models to test on baseline models and picked the best two performing models. The two best performing models were CatBoostClassifier and LGBMClassifier. Also because "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "from time import time\n",
    "import pprint\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "classifiers = []\n",
    "\n",
    "# Model 1 XGBClassifier\n",
    "model1 = XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "\n",
    "# Model 2 SVC\n",
    "model2 = SVC()\n",
    "classifiers.append(model2)\n",
    "\n",
    "# Model 3 DecisionTreeClassifier\n",
    "model3 = DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "\n",
    "# Model 4 RandomForestClassifier\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "\n",
    "# Model 5 GaussianNB\n",
    "model5 = GaussianNB()\n",
    "classifiers.append(model5)\n",
    "\n",
    "# Model 6 CatBoostClassifier\n",
    "model6 = CatBoostClassifier(verbose=False)\n",
    "classifiers.append(model6)\n",
    "\n",
    "# Model 7 LGBMClassifier\n",
    "model7 = LGBMClassifier()\n",
    "classifiers.append(model7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      " Accuracy: 0.9012368815592204 \n",
      " Duration: 22.660205125808716\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) \n",
      " Accuracy: 0.8481384307846077 \n",
      " Duration: 28.23619818687439\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      " Accuracy: 0.8159670164917541 \n",
      " Duration: 3.829073905944824\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) \n",
      " Accuracy: 0.8751874062968515 \n",
      " Duration: 22.206252098083496\n",
      "GaussianNB(priors=None, var_smoothing=1e-09) \n",
      " Accuracy: 0.8683158420789605 \n",
      " Duration: 0.06083822250366211\n",
      "<catboost.core.CatBoostClassifier object at 0x1a21610cd0> \n",
      " Accuracy: 0.9761369315342329 \n",
      " Duration: 25.888486862182617\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) \n",
      " Accuracy: 0.9582083958020989 \n",
      " Duration: 2.3355648517608643\n"
     ]
    }
   ],
   "source": [
    "# Loop for training the basic models\n",
    "for clf in classifiers:\n",
    "    start = time()\n",
    "    clf.fit(imputed_training, y_train)\n",
    "    stop = time()\n",
    "    y_pred= clf.predict(imputed_validation)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    duration = stop-start\n",
    "    print(\"%s \\n Accuracy: %s \\n Duration: %s\"%(clf, acc, duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost\n",
    "Besides performing as one of the best of the tested classification models, CatBoost creates better results with less data and less tuning compared to other models, has fast computation, and its impressive handling of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 35, 68, 93]\n"
     ]
    }
   ],
   "source": [
    "# Create random seed\n",
    "seed = 67\n",
    "\n",
    "# Setting categorical\n",
    "categorical_names = ['x34', 'x35', 'x68', 'x93']\n",
    "categoricals = [imputed_training.columns.get_loc(i) for i in categorical_names]\n",
    "df_names = [imputed_training, imputed_validation, imputed_test]\n",
    "print(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting category columns\n",
    "for i in df_names:\n",
    "    for ii in categorical_names:\n",
    "        i[ii] = i[ii].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Optimization Function\n",
    "def opt_performance(optimizer, X, y, title, callbacks=None):\n",
    "    \"\"\"\n",
    "    To fit and capture the performance and time. Meant to be used with Catboost and Lightgbm.\n",
    "    \n",
    "    optimizer = skopt optimizer\n",
    "    X = the training set \n",
    "    y = our target\n",
    "    title = a string label for the experiment\n",
    "    \n",
    "    best_params: outputs best performing parameter models\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    if callbacks:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "    optimizer.fit(X, y)\n",
    "    results = pd.DataFrame(optimizer.cv_results_)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = results.iloc[optimizer.best_index_].std_test_score\n",
    "    best_params = optimizer.best_params_\n",
    "    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n",
    "           +u\"\\u00B1\"+\" %.3f\") % (time() - start, \n",
    "                                  len(optimizer.cv_results_['params']),\n",
    "                                  best_score,\n",
    "                                  best_score_std))    \n",
    "    print('Best parameters:')\n",
    "    pprint.pprint(best_params)\n",
    "    print()\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scorer for AUC\n",
    "roc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cat = CatBoostClassifier(thread_count=2,\n",
    "                         loss_function='Logloss',\n",
    "                         od_type = 'Iter',\n",
    "                         verbose= False,\n",
    "                         cat_features=categoricals\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining your search space\n",
    "space4catboost = {'iterations': Integer(100, 1000),\n",
    "                 'depth': Integer(5, 10),\n",
    "                 'learning_rate': Real(0.01, 0.5, 'log-uniform'),\n",
    "                 'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "                 'bagging_temperature': Real(0.0, 1.0),\n",
    "                 'border_count': Integer(32, 255),\n",
    "                 'l2_leaf_reg': Integer(2, 5),\n",
    "                 'scale_pos_weight':Real(0.01, 1.0, 'uniform')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up BayesSearchCV\n",
    "opt_cat = BayesSearchCV(clf_cat,\n",
    "                    space4catboost,\n",
    "                    scoring=roc_auc,\n",
    "                    cv=skf,\n",
    "                    n_iter=100,\n",
    "                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost took 15368.61 seconds,  candidates checked: 100, best CV score: 0.989 Â± 0.002\n",
      "Best parameters:\n",
      "OrderedDict([('bagging_temperature', 0.0),\n",
      "             ('border_count', 255),\n",
      "             ('depth', 9),\n",
      "             ('iterations', 1000),\n",
      "             ('l2_leaf_reg', 5),\n",
      "             ('learning_rate', 0.1825499244262304),\n",
      "             ('random_strength', 1e-09),\n",
      "             ('scale_pos_weight', 1.0)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params_cat = opt_performance(opt_cat, imputed_training, y_train,'CatBoost',\n",
    "                                       callbacks=[DeltaXStopper(0.001),\n",
    "                                                  DeadlineStopper(100*5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 11s, sys: 48.2 s, total: 8min\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a3b48c410>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tuned_model_cat = CatBoostClassifier(**best_params_cat,od_type='Iter',one_hot_max_size=10, verbose=False, random_seed=seed)\n",
    "tuned_model_cat.fit(imputed_training,y_train, cat_features=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC score: 0.9875851857059373\n",
      "CPU times: user 157 ms, sys: 92.7 ms, total: 250 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_cat = tuned_model_cat.predict_proba(imputed_validation)[:, 1]\n",
    "valid_score_cat = roc_auc_score(y_valid, y_pred_cat)\n",
    "print('Validation ROC-AUC score:', valid_score_cat)\n",
    "##ROC_AUC is 0.9880908960669734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('bagging_temperature', 0.0),\n",
      "             ('border_count', 255),\n",
      "             ('depth', 9),\n",
      "             ('iterations', 1000),\n",
      "             ('l2_leaf_reg', 5),\n",
      "             ('learning_rate', 0.1825499244262304),\n",
      "             ('random_strength', 1e-09),\n",
      "             ('scale_pos_weight', 1.0)])\n",
      "CPU times: user 7min 22s, sys: 50.9 s, total: 8min 13s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuned_model_cat = CatBoostClassifier(**best_params_cat,od_type='Iter',one_hot_max_size=10,verbose=False, random_seed=seed)\n",
    "tuned_model_cat.fit(imputed_training,y_train, cat_features=categoricals)\n",
    "pprint.pprint(best_params_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_best_params = {'iterations': 1000,\n",
    "                   'depth': 9,\n",
    "                   'learning_rate': 0.1825499244262304,\n",
    "                   'random_strength': 1e-9,\n",
    "                   'bagging_temperature': 0,\n",
    "                   'border_count': 255,\n",
    "                   'l2_leaf_reg': 5,\n",
    "                   'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgbm = LGBMClassifier(thread_count=2,\n",
    "                          loss_function='Logloss',\n",
    "                          od_type = 'Iter',\n",
    "                          verbose=0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining your search space\n",
    "space4lightgbm = {'num_leaves': Integer(10, 50),\n",
    "                  'max_depth': Integer(5, 10),\n",
    "                  'learning_rate': Real(0.01, 0.5, 'log-uniform'),\n",
    "                  'lambda_l2': Real(0.0001, 5.0, 'log-uniform'),\n",
    "                  'min_child_samples': Integer(0, 200),\n",
    "                  'min_child_weight': Integer(0, 10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up BayesSearchCV\n",
    "opt_lightgbm = BayesSearchCV(clf_lgbm,\n",
    "                             space4lightgbm,\n",
    "                             scoring=roc_auc,\n",
    "                             cv=skf,\n",
    "                             n_iter=100,\n",
    "                             n_jobs=1,\n",
    "                             return_train_score=False,\n",
    "                             refit=True,\n",
    "                             optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                             random_state=seed,\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM took 919.22 seconds,  candidates checked: 100, best CV score: 0.987 Â± 0.001\n",
      "Best parameters:\n",
      "OrderedDict([('lambda_l2', 0.0001),\n",
      "             ('learning_rate', 0.2673475162170724),\n",
      "             ('max_depth', 10),\n",
      "             ('min_child_samples', 200),\n",
      "             ('min_child_weight', 0),\n",
      "             ('num_leaves', 40)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params_lightgbm = opt_performance(opt_lightgbm, imputed_training, y_train,'LightGBM',\n",
    "                                       callbacks=[DeltaXStopper(0.0001),\n",
    "                                                  DeadlineStopper(100*5)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.25 s, sys: 319 ms, total: 8.57 s\n",
      "Wall time: 1.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', lambda_l2=0.0001,\n",
       "               learning_rate=0.2673475162170724, max_depth=10,\n",
       "               min_child_samples=200, min_child_weight=0, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=40, objective=None,\n",
       "               od_type='Iter', one_hot_max_size=10, random_seed=67,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "               verbose=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tuned_model_lgbm = LGBMClassifier(**best_params_lightgbm,od_type='Iter',one_hot_max_size=10, verbose=0, random_seed=seed)\n",
    "tuned_model_lgbm.fit(imputed_training,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC score: 0.9844737806952922\n",
      "CPU times: user 939 ms, sys: 109 ms, total: 1.05 s\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_lgbm = tuned_model_lgbm.predict_proba(imputed_validation)[:, 1]\n",
    "valid_score_lgbm = roc_auc_score(y_valid, y_pred_lgbm)\n",
    "print('Validation ROC-AUC score:', valid_score_lgbm)\n",
    "##ROC_AUC is 0.8056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CAT ROC-AUC score: 0.9875851857059373\n",
      "Validation LGBM ROC-AUC score: 0.9844737806952922\n"
     ]
    }
   ],
   "source": [
    "# Comparing the two models\n",
    "print('Validation CAT ROC-AUC score:', valid_score_cat)\n",
    "print('Validation LGBM ROC-AUC score:', valid_score_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.27 s, sys: 231 ms, total: 8.5 s\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', lambda_l2=0.0001,\n",
       "               learning_rate=0.2673475162170724, max_depth=10,\n",
       "               min_child_samples=200, min_child_weight=0, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=40, objective=None,\n",
       "               od_type='Iter', one_hot_max_size=10, random_seed=67,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "               verbose=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tuned_model_lgbm = LGBMClassifier(**best_params_lightgbm,od_type='Iter',one_hot_max_size=10, verbose=0, random_seed=seed)\n",
    "tuned_model_lgbm.fit(imputed_training,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final LightGBM\n",
    "\n",
    "best_params_lightgbm = {'num_leaves': 40,\n",
    "                        'max_depth': 10,\n",
    "                        'learning_rate': 0.2673475162170724,\n",
    "                        'lambda_l2': 0.0001,\n",
    "                        'num_iterations': 200,\n",
    "                        'min_child_samples': 200,\n",
    "                        'min_child_weight': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using two models\n",
    "y_pred_lgbm = tuned_model_lgbm.predict(imputed_validation)\n",
    "y_pred_catboost = tuned_model_cat.predict(imputed_validation)\n",
    "\n",
    "# Score validation\n",
    "lgbm_validation = roc_auc_score(y_valid, y_pred_lgbm)\n",
    "catboost_validation = roc_auc_score(y_valid, y_pred_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score LGBM ROC-AUC score: 0.9415704780358917\n",
      "Test Score CAT ROC-AUC score: 0.9540364074150559\n"
     ]
    }
   ],
   "source": [
    "# Comparing the two models\n",
    "print('Test Score LGBM ROC-AUC score:', lgbm_validation)\n",
    "print('Test Score CAT ROC-AUC score:', catboost_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Accuracy score:  0.9720139930034982\n",
      "CAT Accuracy score:  0.9793853073463268\n",
      "LGBM Precision score:  0.9664179104477612\n",
      "CAT Precision score:  0.9838056680161943\n",
      "LGBM Recall score:  0.8908692933083177\n",
      "CAT Recall score:  0.9118198874296435\n",
      "LGBM AUC score:  0.9415704780358917\n",
      "CAT AUC score:  0.9540364074150559\n",
      "LGBM Confusion Matrix: \n",
      "array([[12711,    99],\n",
      "       [  349,  2849]])\n",
      "LGBM Confusion Matrix: \n",
      "array([[12762,    48],\n",
      "       [  282,  2916]])\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "print('LGBM Accuracy score: ', accuracy_score(y_valid, y_pred_lgbm))\n",
    "print('CAT Accuracy score: ', accuracy_score(y_valid, y_pred_catboost))\n",
    "\n",
    "print('LGBM Precision score: ', precision_score(y_valid, y_pred_lgbm))\n",
    "print('CAT Precision score: ', precision_score(y_valid, y_pred_catboost))\n",
    "\n",
    "print('LGBM Recall score: ', recall_score(y_valid, y_pred_lgbm))\n",
    "print('CAT Recall score: ', recall_score(y_valid, y_pred_catboost))\n",
    "\n",
    "print('LGBM AUC score: ', roc_auc_score(y_valid, y_pred_lgbm))\n",
    "print('CAT AUC score: ', roc_auc_score(y_valid, y_pred_catboost))\n",
    "\n",
    "print('LGBM Confusion Matrix: ')\n",
    "pprint.pprint(confusion_matrix(y_valid, y_pred_lgbm))\n",
    "print('LGBM Confusion Matrix: ')\n",
    "pprint.pprint(confusion_matrix(y_valid, y_pred_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make predictions using the features from the test data set\n",
    "predictions_lgbm = tuned_model_lgbm.predict(imputed_test)\n",
    "predictions_cat = tuned_model_cat.predict(imputed_test)\n",
    "\n",
    "\n",
    "#Display our predictions - they are either 0 or 1 for each training instance \n",
    "#depending on whether our algorithm believes the person survived or not.\n",
    "predictions_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "file1 = pd.DataFrame({'Predicted':predictions_lgbm})\n",
    "file2 = pd.DataFrame({'Predicted':predictions_cat})\n",
    "\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename1 = 'results1.csv'\n",
    "filename2 = 'results2.csv'\n",
    "\n",
    "file1.to_csv(filename1,index=False)\n",
    "file2.to_csv(filename2,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
